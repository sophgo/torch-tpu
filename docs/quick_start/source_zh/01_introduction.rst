TORCH-TPU简介
============

为支持算能深度学习处理器TPU，本项目定制开发了开源人工智能编程框架PyTorch（以下代称为
torch_tpu），为使用PyTorch框架的开发者提供TPU处理器的超强算力。

在开发设计过程中，Torch模块中与TPU相关的接口的语义与CPU和GPU的接口语义保持一致，这
使得使用者可以快捷地通过Torch模块调用TPU后端支持的网络运算，同时实现CPU和TPU之间的切换转接。

TORCH-TPU在使用方式和风格上与原生PyTorch保持一致 为了方便用户快速上手使用TPU设备，TORCH-TPU在设计上遵循以下规则：

· 通过Torch模块可调用TPU后端支持的网络运算，并且支持数据在CPU和TPU之间的无缝切换。

· 最大限度的遵循PyTorch原生的体系结构，保留框架本身出色的特性，比如自动微分、动态分发、Debug等。

· 用户在将模型移植到算能TPU设备进行训练时，在开发方式和代码重用方面做到最小的改动，确保迁移成本的最小化。

本手册主要介绍了torch_tpu在算能深度学习处理器TPU上的安装部署方法。
