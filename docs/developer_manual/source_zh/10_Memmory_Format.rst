内存管理机制声明
============

本章节介绍TORCH-TPU中的内存管理机制。

背景介绍
--------------------

TORCH-TPU框架中可见的内存主要为主机Host端的内存，以及设备端TPU内存两部分。

TPU计算发生时，要求所有的数据位于TPU内存当中。

模型保存、CPU对模型参数进行初始化、CPU执行某些计算需要数据内存位于Host的内存当中。

为此，TPU内存与Host内存需要数据的交互。

通常情况下，数据的存储格式（Layout）为紧密存储格式（Contiguous Layout），算子按照 Contiguous Layout 进行读取和存储即可。

当有shape相关算子参与时，为了较少数据的拷贝时间，通常使用一组名为Stride的参数来表述数据的位置。

该情况下，对CPU是较为友好的，因为CPU更加擅长串行的执行逻辑，并行的数量相对较少，这意味着每次只需要读取有限的相对独立数字即可。

TPU是一种利用并行计算来加速运算的设备，同时可以执行许多数字的运算，前提是能够一次性的读取数字到其Local Memmory当中。

当有Strided的数据存在时，对于TPU就不是很友好了。

并且，TPU的加速计算指令对于某些运算需要特殊的排列方式。

当前，TPU和CPU上的数据排布按照相同的方式。对于TPU而言，执行一些运算，可能需要做一些额外的数据拷贝，才能完成。

因此，这里需要一种CPU上的数据存储和TPU上的数据存储相互映射的一直机制。使得TPU上的数据排布相对友好。


整体思路和框架设计
--------------------



相关实现
--------------------

 -- TPUStorageImpl : 实现对TPU物理内存的表述补丁。对C10:StorageImpl继承，用于构建Tensor。