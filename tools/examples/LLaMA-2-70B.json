{
    "superParSel": true,
    
    "name": "LLaMA-2-70B",
    "block_size": 128,

    "layer_num": 80,
    "intermediate_size": 28672,
    "vocab_size": 32000,
    "head": 64,
    "kv_heads": 8,
    "token_size" : 4096
}